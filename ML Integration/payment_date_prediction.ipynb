{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wcq6dWzy1ZR0",
   "metadata": {
    "id": "wcq6dWzy1ZR0"
   },
   "source": [
    "# Payment Date Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778654e",
   "metadata": {
    "id": "2778654e"
   },
   "source": [
    "\n",
    "### Importing related Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304c9e38",
   "metadata": {
    "id": "304c9e38"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import datetime as dt\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#sklearn packages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724f5ee",
   "metadata": {
    "id": "8724f5ee"
   },
   "source": [
    "### Store the dataset into the Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415db50a",
   "metadata": {
    "id": "415db50a"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e37f05",
   "metadata": {
    "id": "42e37f05"
   },
   "source": [
    "### Check the shape of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cc0907",
   "metadata": {
    "id": "27cc0907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50099, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c955d",
   "metadata": {
    "id": "b68c955d"
   },
   "source": [
    "### Check the Detail information of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e092ec9e",
   "metadata": {
    "id": "e092ec9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50099 entries, 0 to 50098\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   business_code           50099 non-null  object \n",
      " 1   cust_number             50099 non-null  object \n",
      " 2   name_customer           50099 non-null  object \n",
      " 3   clear_date              40000 non-null  object \n",
      " 4   buisness_year           50099 non-null  int64  \n",
      " 5   doc_id                  50099 non-null  int64  \n",
      " 6   posting_date            50099 non-null  object \n",
      " 7   document_create_date    50099 non-null  int64  \n",
      " 8   document_create_date.1  50099 non-null  int64  \n",
      " 9   due_in_date             50099 non-null  int64  \n",
      " 10  invoice_currency        50099 non-null  object \n",
      " 11  document type           50099 non-null  object \n",
      " 12  posting_id              50099 non-null  int64  \n",
      " 13  area_business           0 non-null      float64\n",
      " 14  total_open_amount       50099 non-null  float64\n",
      " 15  baseline_create_date    50099 non-null  int64  \n",
      " 16  cust_payment_terms      50099 non-null  object \n",
      " 17  invoice_id              50093 non-null  float64\n",
      " 18  isOpen                  50099 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(8)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f2d0e",
   "metadata": {
    "id": "112f2d0e"
   },
   "source": [
    "### Display All the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1416e2fd",
   "metadata": {
    "id": "1416e2fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_code', 'cust_number', 'name_customer', 'clear_date',\n",
       "       'buisness_year', 'doc_id', 'posting_date', 'document_create_date',\n",
       "       'document_create_date.1', 'due_in_date', 'invoice_currency',\n",
       "       'document type', 'posting_id', 'area_business', 'total_open_amount',\n",
       "       'baseline_create_date', 'cust_payment_terms', 'invoice_id', 'isOpen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465ed7a",
   "metadata": {
    "id": "d465ed7a"
   },
   "source": [
    "### Describe the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f65e1b",
   "metadata": {
    "id": "25f65e1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>document_create_date</th>\n",
       "      <th>document_create_date.1</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>area_business</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>isOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50099.000000</td>\n",
       "      <td>5.009900e+04</td>\n",
       "      <td>5.009900e+04</td>\n",
       "      <td>5.009900e+04</td>\n",
       "      <td>5.009900e+04</td>\n",
       "      <td>50099.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50099.000000</td>\n",
       "      <td>5.009900e+04</td>\n",
       "      <td>5.009300e+04</td>\n",
       "      <td>50099.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019.307072</td>\n",
       "      <td>2.014112e+09</td>\n",
       "      <td>2.019353e+07</td>\n",
       "      <td>2.019355e+07</td>\n",
       "      <td>2.019369e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32456.565546</td>\n",
       "      <td>2.019355e+07</td>\n",
       "      <td>2.013216e+09</td>\n",
       "      <td>0.201581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.461284</td>\n",
       "      <td>2.912992e+08</td>\n",
       "      <td>4.501712e+03</td>\n",
       "      <td>4.487779e+03</td>\n",
       "      <td>4.475909e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39259.249400</td>\n",
       "      <td>4.488339e+03</td>\n",
       "      <td>2.795573e+08</td>\n",
       "      <td>0.401185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.928502e+09</td>\n",
       "      <td>2.018123e+07</td>\n",
       "      <td>2.018123e+07</td>\n",
       "      <td>2.018122e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>2.018121e+07</td>\n",
       "      <td>1.928502e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.929343e+09</td>\n",
       "      <td>2.019051e+07</td>\n",
       "      <td>2.019051e+07</td>\n",
       "      <td>2.019052e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4943.480000</td>\n",
       "      <td>2.019051e+07</td>\n",
       "      <td>1.929343e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.929968e+09</td>\n",
       "      <td>2.019091e+07</td>\n",
       "      <td>2.019091e+07</td>\n",
       "      <td>2.019093e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17700.000000</td>\n",
       "      <td>2.019091e+07</td>\n",
       "      <td>1.929968e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.930621e+09</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>2.020022e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47385.590000</td>\n",
       "      <td>2.020013e+07</td>\n",
       "      <td>1.930621e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.500000e+09</td>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>2.020071e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>668593.360000</td>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>2.960636e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buisness_year        doc_id  document_create_date  \\\n",
       "count   50099.000000  5.009900e+04          5.009900e+04   \n",
       "mean     2019.307072  2.014112e+09          2.019353e+07   \n",
       "std         0.461284  2.912992e+08          4.501712e+03   \n",
       "min      2019.000000  1.928502e+09          2.018123e+07   \n",
       "25%      2019.000000  1.929343e+09          2.019051e+07   \n",
       "50%      2019.000000  1.929968e+09          2.019091e+07   \n",
       "75%      2020.000000  1.930621e+09          2.020013e+07   \n",
       "max      2020.000000  9.500000e+09          2.020052e+07   \n",
       "\n",
       "       document_create_date.1   due_in_date  posting_id  area_business  \\\n",
       "count            5.009900e+04  5.009900e+04     50099.0            0.0   \n",
       "mean             2.019355e+07  2.019369e+07         1.0            NaN   \n",
       "std              4.487779e+03  4.475909e+03         0.0            NaN   \n",
       "min              2.018123e+07  2.018122e+07         1.0            NaN   \n",
       "25%              2.019051e+07  2.019052e+07         1.0            NaN   \n",
       "50%              2.019091e+07  2.019093e+07         1.0            NaN   \n",
       "75%              2.020013e+07  2.020022e+07         1.0            NaN   \n",
       "max              2.020052e+07  2.020071e+07         1.0            NaN   \n",
       "\n",
       "       total_open_amount  baseline_create_date    invoice_id        isOpen  \n",
       "count       50099.000000          5.009900e+04  5.009300e+04  50099.000000  \n",
       "mean        32456.565546          2.019355e+07  2.013216e+09      0.201581  \n",
       "std         39259.249400          4.488339e+03  2.795573e+08      0.401185  \n",
       "min             0.720000          2.018121e+07  1.928502e+09      0.000000  \n",
       "25%          4943.480000          2.019051e+07  1.929343e+09      0.000000  \n",
       "50%         17700.000000          2.019091e+07  1.929968e+09      0.000000  \n",
       "75%         47385.590000          2.020013e+07  1.930621e+09      0.000000  \n",
       "max        668593.360000          2.020052e+07  2.960636e+09      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c8d02",
   "metadata": {
    "id": "0f2c8d02"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Show top 5 records from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f876212",
   "metadata": {
    "id": "8f876212"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_code</th>\n",
       "      <th>cust_number</th>\n",
       "      <th>name_customer</th>\n",
       "      <th>clear_date</th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>document_create_date</th>\n",
       "      <th>document_create_date.1</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>invoice_currency</th>\n",
       "      <th>document type</th>\n",
       "      <th>posting_id</th>\n",
       "      <th>area_business</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>cust_payment_terms</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>isOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR corp</td>\n",
       "      <td>11-02-2020 00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>1930438491</td>\n",
       "      <td>26-01-2020</td>\n",
       "      <td>20200125</td>\n",
       "      <td>20200126</td>\n",
       "      <td>20200210</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54273.28</td>\n",
       "      <td>20200126</td>\n",
       "      <td>NAH4</td>\n",
       "      <td>1.930438e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U001</td>\n",
       "      <td>200980828</td>\n",
       "      <td>BEN E</td>\n",
       "      <td>08-08-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929646410</td>\n",
       "      <td>22-07-2019</td>\n",
       "      <td>20190722</td>\n",
       "      <td>20190722</td>\n",
       "      <td>20190811</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79656.60</td>\n",
       "      <td>20190722</td>\n",
       "      <td>NAD1</td>\n",
       "      <td>1.929646e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U001</td>\n",
       "      <td>200792734</td>\n",
       "      <td>MDV/ trust</td>\n",
       "      <td>30-12-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929873765</td>\n",
       "      <td>14-09-2019</td>\n",
       "      <td>20190914</td>\n",
       "      <td>20190914</td>\n",
       "      <td>20190929</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2253.86</td>\n",
       "      <td>20190914</td>\n",
       "      <td>NAA8</td>\n",
       "      <td>1.929874e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA02</td>\n",
       "      <td>140105686</td>\n",
       "      <td>SYSC llc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2960623488</td>\n",
       "      <td>30-03-2020</td>\n",
       "      <td>20200330</td>\n",
       "      <td>20200330</td>\n",
       "      <td>20200410</td>\n",
       "      <td>CAD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3299.70</td>\n",
       "      <td>20200331</td>\n",
       "      <td>CA10</td>\n",
       "      <td>2.960623e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR foundation</td>\n",
       "      <td>25-11-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1930147974</td>\n",
       "      <td>13-11-2019</td>\n",
       "      <td>20191113</td>\n",
       "      <td>20191113</td>\n",
       "      <td>20191128</td>\n",
       "      <td>USD</td>\n",
       "      <td>RV</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33133.29</td>\n",
       "      <td>20191113</td>\n",
       "      <td>NAH4</td>\n",
       "      <td>1.930148e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business_code cust_number       name_customer        clear_date  \\\n",
       "0          U001   200769623        WAL-MAR corp  11-02-2020 00:00   \n",
       "1          U001   200980828              BEN E   08-08-2019 00:00   \n",
       "2          U001   200792734          MDV/ trust  30-12-2019 00:00   \n",
       "3          CA02   140105686            SYSC llc               NaN   \n",
       "4          U001   200769623  WAL-MAR foundation  25-11-2019 00:00   \n",
       "\n",
       "   buisness_year      doc_id posting_date  document_create_date  \\\n",
       "0           2020  1930438491   26-01-2020              20200125   \n",
       "1           2019  1929646410   22-07-2019              20190722   \n",
       "2           2019  1929873765   14-09-2019              20190914   \n",
       "3           2020  2960623488   30-03-2020              20200330   \n",
       "4           2019  1930147974   13-11-2019              20191113   \n",
       "\n",
       "   document_create_date.1  due_in_date invoice_currency document type  \\\n",
       "0                20200126     20200210              USD            RV   \n",
       "1                20190722     20190811              USD            RV   \n",
       "2                20190914     20190929              USD            RV   \n",
       "3                20200330     20200410              CAD            RV   \n",
       "4                20191113     20191128              USD            RV   \n",
       "\n",
       "   posting_id  area_business  total_open_amount  baseline_create_date  \\\n",
       "0           1            NaN           54273.28              20200126   \n",
       "1           1            NaN           79656.60              20190722   \n",
       "2           1            NaN            2253.86              20190914   \n",
       "3           1            NaN            3299.70              20200331   \n",
       "4           1            NaN           33133.29              20191113   \n",
       "\n",
       "  cust_payment_terms    invoice_id  isOpen  \n",
       "0               NAH4  1.930438e+09       0  \n",
       "1               NAD1  1.929646e+09       0  \n",
       "2               NAA8  1.929874e+09       0  \n",
       "3               CA10  2.960623e+09       1  \n",
       "4               NAH4  1.930148e+09       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b044e4",
   "metadata": {
    "id": "92b044e4"
   },
   "source": [
    "### Display the Null values percentage against every columns (compare to the total number of records)\n",
    "\n",
    "- Output expected : area_business - 100% null, clear_data = 20% null, invoice_id = 0.12% null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c7b13d",
   "metadata": {
    "id": "24c7b13d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_code               0.00\n",
       "cust_number                 0.00\n",
       "name_customer               0.00\n",
       "clear_date                 20.16\n",
       "buisness_year               0.00\n",
       "doc_id                      0.00\n",
       "posting_date                0.00\n",
       "document_create_date        0.00\n",
       "document_create_date.1      0.00\n",
       "due_in_date                 0.00\n",
       "invoice_currency            0.00\n",
       "document type               0.00\n",
       "posting_id                  0.00\n",
       "area_business             100.00\n",
       "total_open_amount           0.00\n",
       "baseline_create_date        0.00\n",
       "cust_payment_terms          0.00\n",
       "invoice_id                  0.01\n",
       "isOpen                      0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46a98b",
   "metadata": {
    "id": "2c46a98b"
   },
   "source": [
    "### Display Invoice_id and Doc_Id\n",
    "\n",
    "- Note - Many of the would have same invoice_id and doc_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038f24bb",
   "metadata": {
    "id": "038f24bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.930438e+09\n",
       "1        1.929646e+09\n",
       "2        1.929874e+09\n",
       "3        2.960623e+09\n",
       "4        1.930148e+09\n",
       "             ...     \n",
       "50094    2.960619e+09\n",
       "50095    2.960619e+09\n",
       "50096    2.960619e+09\n",
       "50097    2.960619e+09\n",
       "50098    2.960619e+09\n",
       "Name: invoice_id, Length: 50099, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['invoice_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40d075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1930438491\n",
       "1        1929646410\n",
       "2        1929873765\n",
       "3        2960623488\n",
       "4        1930147974\n",
       "            ...    \n",
       "50094    2960618884\n",
       "50095    2960618885\n",
       "50096    2960618886\n",
       "50097    2960618887\n",
       "50098    2960618888\n",
       "Name: doc_id, Length: 50099, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['doc_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfe10a",
   "metadata": {
    "id": "18cfe10a"
   },
   "source": [
    "#### Write a code to check - 'baseline_create_date',\"document_create_date\",'document_create_date.1' - these columns are almost same.\n",
    "\n",
    "- Please note, if they are same, we need to drop them later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5b40ff",
   "metadata": {
    "id": "cf5b40ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same/Different\n",
      "Different         34078\n",
      "Same              16021\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "check = np.where((df['baseline_create_date'] == df['document_create_date']) & (df['baseline_create_date'] == df['document_create_date.1']), \"Same\", \"Different\")\n",
    "check1=pd.DataFrame(check,columns=['Same/Different'])\n",
    "print(check1.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33110576",
   "metadata": {
    "id": "33110576"
   },
   "source": [
    "#### Please check, Column 'posting_id' is constant columns or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecce2664",
   "metadata": {
    "id": "ecce2664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['posting_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb8daf",
   "metadata": {
    "id": "e5fb8daf"
   },
   "source": [
    "#### Please check 'isOpen' is a constant column and relevant column for this project or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db9956b",
   "metadata": {
    "id": "8db9956b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    40000\n",
      "1    10099\n",
      "Name: isOpen, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['isOpen'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a11a62",
   "metadata": {
    "id": "45a11a62"
   },
   "source": [
    "### Write the code to drop all the following columns from the dataframe\n",
    "\n",
    "- 'area_business'\n",
    "- \"posting_id\"\n",
    "- \"invoice_id\"\n",
    "- \"document_create_date\"\n",
    "- \"isOpen\"\n",
    "- 'document type' \n",
    "- 'document_create_date.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270d85d1",
   "metadata": {
    "id": "270d85d1"
   },
   "outputs": [],
   "source": [
    "df_copy=df.copy()\n",
    "df.drop(['area_business', \"posting_id\", \"invoice_id\", \"document_create_date\", \"isOpen\", 'document type' \n",
    "         , 'document_create_date.1'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K5LHAM2XVGnk",
   "metadata": {
    "id": "K5LHAM2XVGnk"
   },
   "source": [
    "### Please check from the dataframe whether all the columns are removed or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3f7d2b",
   "metadata": {
    "id": "ef3f7d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_code', 'cust_number', 'name_customer', 'clear_date',\n",
      "       'buisness_year', 'doc_id', 'posting_date', 'due_in_date',\n",
      "       'invoice_currency', 'total_open_amount', 'baseline_create_date',\n",
      "       'cust_payment_terms'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_code</th>\n",
       "      <th>cust_number</th>\n",
       "      <th>name_customer</th>\n",
       "      <th>clear_date</th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>invoice_currency</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>cust_payment_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR corp</td>\n",
       "      <td>11-02-2020 00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>1930438491</td>\n",
       "      <td>26-01-2020</td>\n",
       "      <td>20200210</td>\n",
       "      <td>USD</td>\n",
       "      <td>54273.28</td>\n",
       "      <td>20200126</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U001</td>\n",
       "      <td>200980828</td>\n",
       "      <td>BEN E</td>\n",
       "      <td>08-08-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929646410</td>\n",
       "      <td>22-07-2019</td>\n",
       "      <td>20190811</td>\n",
       "      <td>USD</td>\n",
       "      <td>79656.60</td>\n",
       "      <td>20190722</td>\n",
       "      <td>NAD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U001</td>\n",
       "      <td>200792734</td>\n",
       "      <td>MDV/ trust</td>\n",
       "      <td>30-12-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929873765</td>\n",
       "      <td>14-09-2019</td>\n",
       "      <td>20190929</td>\n",
       "      <td>USD</td>\n",
       "      <td>2253.86</td>\n",
       "      <td>20190914</td>\n",
       "      <td>NAA8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA02</td>\n",
       "      <td>140105686</td>\n",
       "      <td>SYSC llc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2960623488</td>\n",
       "      <td>30-03-2020</td>\n",
       "      <td>20200410</td>\n",
       "      <td>CAD</td>\n",
       "      <td>3299.70</td>\n",
       "      <td>20200331</td>\n",
       "      <td>CA10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR foundation</td>\n",
       "      <td>25-11-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1930147974</td>\n",
       "      <td>13-11-2019</td>\n",
       "      <td>20191128</td>\n",
       "      <td>USD</td>\n",
       "      <td>33133.29</td>\n",
       "      <td>20191113</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business_code cust_number       name_customer        clear_date  \\\n",
       "0          U001   200769623        WAL-MAR corp  11-02-2020 00:00   \n",
       "1          U001   200980828              BEN E   08-08-2019 00:00   \n",
       "2          U001   200792734          MDV/ trust  30-12-2019 00:00   \n",
       "3          CA02   140105686            SYSC llc               NaN   \n",
       "4          U001   200769623  WAL-MAR foundation  25-11-2019 00:00   \n",
       "\n",
       "   buisness_year      doc_id posting_date  due_in_date invoice_currency  \\\n",
       "0           2020  1930438491   26-01-2020     20200210              USD   \n",
       "1           2019  1929646410   22-07-2019     20190811              USD   \n",
       "2           2019  1929873765   14-09-2019     20190929              USD   \n",
       "3           2020  2960623488   30-03-2020     20200410              CAD   \n",
       "4           2019  1930147974   13-11-2019     20191128              USD   \n",
       "\n",
       "   total_open_amount  baseline_create_date cust_payment_terms  \n",
       "0           54273.28              20200126               NAH4  \n",
       "1           79656.60              20190722               NAD1  \n",
       "2            2253.86              20190914               NAA8  \n",
       "3            3299.70              20200331               CA10  \n",
       "4           33133.29              20191113               NAH4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc052c7",
   "metadata": {
    "id": "6bc052c7"
   },
   "source": [
    "### Show all the Duplicate rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ae3c7e4",
   "metadata": {
    "id": "1ae3c7e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_code</th>\n",
       "      <th>cust_number</th>\n",
       "      <th>name_customer</th>\n",
       "      <th>clear_date</th>\n",
       "      <th>buisness_year</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>due_in_date</th>\n",
       "      <th>invoice_currency</th>\n",
       "      <th>total_open_amount</th>\n",
       "      <th>baseline_create_date</th>\n",
       "      <th>cust_payment_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR in</td>\n",
       "      <td>12-03-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1928870382</td>\n",
       "      <td>28-02-2019</td>\n",
       "      <td>20190315</td>\n",
       "      <td>USD</td>\n",
       "      <td>19557.41</td>\n",
       "      <td>20190228</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR trust</td>\n",
       "      <td>28-08-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929758460</td>\n",
       "      <td>18-08-2019</td>\n",
       "      <td>20190902</td>\n",
       "      <td>USD</td>\n",
       "      <td>5600.41</td>\n",
       "      <td>20190818</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR corporation</td>\n",
       "      <td>16-12-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1930216806</td>\n",
       "      <td>04-12-2019</td>\n",
       "      <td>20191219</td>\n",
       "      <td>USD</td>\n",
       "      <td>35352.17</td>\n",
       "      <td>20191204</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>U001</td>\n",
       "      <td>200769623</td>\n",
       "      <td>WAL-MAR</td>\n",
       "      <td>22-11-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1930137035</td>\n",
       "      <td>12-11-2019</td>\n",
       "      <td>20191127</td>\n",
       "      <td>USD</td>\n",
       "      <td>2982.64</td>\n",
       "      <td>20191112</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>CA02</td>\n",
       "      <td>140104409</td>\n",
       "      <td>LOB associates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2960628616</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>20200425</td>\n",
       "      <td>CAD</td>\n",
       "      <td>82975.82</td>\n",
       "      <td>20200415</td>\n",
       "      <td>CA10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49963</th>\n",
       "      <td>U001</td>\n",
       "      <td>200759878</td>\n",
       "      <td>SA us</td>\n",
       "      <td>29-01-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1928613993</td>\n",
       "      <td>13-01-2019</td>\n",
       "      <td>20190128</td>\n",
       "      <td>USD</td>\n",
       "      <td>10968.24</td>\n",
       "      <td>20190113</td>\n",
       "      <td>NAH4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49986</th>\n",
       "      <td>U001</td>\n",
       "      <td>200772670</td>\n",
       "      <td>ASSOCIAT foundation</td>\n",
       "      <td>12-06-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929403090</td>\n",
       "      <td>29-05-2019</td>\n",
       "      <td>20190613</td>\n",
       "      <td>USD</td>\n",
       "      <td>155837.53</td>\n",
       "      <td>20190529</td>\n",
       "      <td>NAU5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49990</th>\n",
       "      <td>U001</td>\n",
       "      <td>200765011</td>\n",
       "      <td>MAINES llc</td>\n",
       "      <td>06-06-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1929365364</td>\n",
       "      <td>22-05-2019</td>\n",
       "      <td>20190606</td>\n",
       "      <td>USD</td>\n",
       "      <td>4008.05</td>\n",
       "      <td>20190522</td>\n",
       "      <td>NAA8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>U001</td>\n",
       "      <td>200704045</td>\n",
       "      <td>RA trust</td>\n",
       "      <td>25-10-2019 00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>1930001131</td>\n",
       "      <td>10-10-2019</td>\n",
       "      <td>20191025</td>\n",
       "      <td>USD</td>\n",
       "      <td>73002.24</td>\n",
       "      <td>20191010</td>\n",
       "      <td>NAA8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>CA02</td>\n",
       "      <td>140106408</td>\n",
       "      <td>WAL-M corp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2960618790</td>\n",
       "      <td>06-03-2020</td>\n",
       "      <td>20200316</td>\n",
       "      <td>CAD</td>\n",
       "      <td>92832.27</td>\n",
       "      <td>20200306</td>\n",
       "      <td>CA10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1162 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      business_code cust_number        name_customer        clear_date  \\\n",
       "1041           U001   200769623           WAL-MAR in  12-03-2019 00:00   \n",
       "2400           U001   200769623        WAL-MAR trust  28-08-2019 00:00   \n",
       "2584           U001   200769623  WAL-MAR corporation  16-12-2019 00:00   \n",
       "3755           U001   200769623             WAL-MAR   22-11-2019 00:00   \n",
       "3873           CA02   140104409       LOB associates               NaN   \n",
       "...             ...         ...                  ...               ...   \n",
       "49963          U001   200759878                SA us  29-01-2019 00:00   \n",
       "49986          U001   200772670  ASSOCIAT foundation  12-06-2019 00:00   \n",
       "49990          U001   200765011           MAINES llc  06-06-2019 00:00   \n",
       "49991          U001   200704045             RA trust  25-10-2019 00:00   \n",
       "50000          CA02   140106408           WAL-M corp               NaN   \n",
       "\n",
       "       buisness_year      doc_id posting_date  due_in_date invoice_currency  \\\n",
       "1041            2019  1928870382   28-02-2019     20190315              USD   \n",
       "2400            2019  1929758460   18-08-2019     20190902              USD   \n",
       "2584            2019  1930216806   04-12-2019     20191219              USD   \n",
       "3755            2019  1930137035   12-11-2019     20191127              USD   \n",
       "3873            2020  2960628616   14-04-2020     20200425              CAD   \n",
       "...              ...         ...          ...          ...              ...   \n",
       "49963           2019  1928613993   13-01-2019     20190128              USD   \n",
       "49986           2019  1929403090   29-05-2019     20190613              USD   \n",
       "49990           2019  1929365364   22-05-2019     20190606              USD   \n",
       "49991           2019  1930001131   10-10-2019     20191025              USD   \n",
       "50000           2020  2960618790   06-03-2020     20200316              CAD   \n",
       "\n",
       "       total_open_amount  baseline_create_date cust_payment_terms  \n",
       "1041            19557.41              20190228               NAH4  \n",
       "2400             5600.41              20190818               NAH4  \n",
       "2584            35352.17              20191204               NAH4  \n",
       "3755             2982.64              20191112               NAH4  \n",
       "3873            82975.82              20200415               CA10  \n",
       "...                  ...                   ...                ...  \n",
       "49963           10968.24              20190113               NAH4  \n",
       "49986          155837.53              20190529               NAU5  \n",
       "49990            4008.05              20190522               NAA8  \n",
       "49991           73002.24              20191010               NAA8  \n",
       "50000           92832.27              20200306               CA10  \n",
       "\n",
       "[1162 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate = df[df.duplicated()]\n",
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fab09",
   "metadata": {
    "id": "464fab09"
   },
   "source": [
    "### Display the Number of Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ea2397",
   "metadata": {
    "id": "b1ea2397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a6718",
   "metadata": {
    "id": "827a6718"
   },
   "source": [
    "### Drop all the Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d10151c",
   "metadata": {
    "id": "5d10151c"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d1f9b",
   "metadata": {
    "id": "7e5d1f9b"
   },
   "source": [
    "#### Now check for all duplicate rows now\n",
    "\n",
    "- Note - It must be 0 by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9accc9fc",
   "metadata": {
    "id": "9accc9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0704898",
   "metadata": {
    "id": "d0704898"
   },
   "source": [
    "### Check for the number of Rows and Columns in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "582748a8",
   "metadata": {
    "id": "582748a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47789, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4o9c5UodWRtl",
   "metadata": {
    "id": "4o9c5UodWRtl"
   },
   "source": [
    "### Find out the total count of null values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0612cb5",
   "metadata": {
    "id": "b0612cb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_code              0\n",
       "cust_number                0\n",
       "name_customer              0\n",
       "clear_date              9464\n",
       "buisness_year              0\n",
       "doc_id                     0\n",
       "posting_date               0\n",
       "due_in_date                0\n",
       "invoice_currency           0\n",
       "total_open_amount          0\n",
       "baseline_create_date       0\n",
       "cust_payment_terms         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdb98b",
   "metadata": {
    "id": "7abdb98b"
   },
   "source": [
    "#Data type Conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPfSUSp-WpPj",
   "metadata": {
    "id": "LPfSUSp-WpPj"
   },
   "source": [
    "### Please check the data type of each column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "689c8592",
   "metadata": {
    "id": "689c8592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_code            object\n",
       "cust_number              object\n",
       "name_customer            object\n",
       "clear_date               object\n",
       "buisness_year             int64\n",
       "doc_id                    int64\n",
       "posting_date             object\n",
       "due_in_date               int64\n",
       "invoice_currency         object\n",
       "total_open_amount       float64\n",
       "baseline_create_date      int64\n",
       "cust_payment_terms       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nsem0_3XzOt",
   "metadata": {
    "id": "0nsem0_3XzOt"
   },
   "source": [
    "### Check the datatype format of below columns\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "-yyODyW3X6pL",
   "metadata": {
    "id": "-yyODyW3X6pL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clear_date              object\n",
       "posting_date            object\n",
       "due_in_date              int64\n",
       "baseline_create_date     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols=['clear_date','posting_date','due_in_date','baseline_create_date']\n",
    "df[date_cols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf9478",
   "metadata": {
    "id": "11cf9478"
   },
   "source": [
    "### converting date columns into date time formats\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date\n",
    "\n",
    "\n",
    "- **Note - You have to convert all these above columns into \"%Y%m%d\" format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a8c6c71",
   "metadata": {
    "id": "9a8c6c71"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data 11-02-2020 00:00 doesn't match format specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2186\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2187\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2188\u001b[0m             \u001b[1;31m# If tzaware, these values represent unix timestamps, so we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17352/1158662566.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clear_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clear_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'posting_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'posting_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'due_in_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'due_in_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'baseline_create_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'baseline_create_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mcache_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mutc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"utc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[0;32m    402\u001b[0m         \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2193\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2173\u001b[0m     \u001b[0morder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"F\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[0;32m   2176\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data 11-02-2020 00:00 doesn't match format specified"
     ]
    }
   ],
   "source": [
    "df['clear_date'] = pd.to_datetime(df['clear_date'],format='%Y-%m-%d')\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'],format='%Y-%m-%d')\n",
    "df['due_in_date'] = pd.to_datetime(df['due_in_date'],format='%Y%m%d')\n",
    "df['baseline_create_date'] = pd.to_datetime(df['baseline_create_date'],format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adq0wSIYSCS",
   "metadata": {
    "id": "7adq0wSIYSCS"
   },
   "source": [
    "### Please check the datatype of all the columns after conversion of the above 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd028c61",
   "metadata": {
    "id": "fd028c61"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9882fa",
   "metadata": {
    "id": "8c9882fa"
   },
   "source": [
    "#### the invoice_currency column contains two different categories, USD and CAD\n",
    "\n",
    "- Please do a count of each currency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72085397",
   "metadata": {
    "id": "72085397"
   },
   "outputs": [],
   "source": [
    "df['invoice_currency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe26ee",
   "metadata": {
    "id": "6cbe26ee"
   },
   "source": [
    "#### display the \"total_open_amount\" column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49f2ab",
   "metadata": {
    "id": "6c49f2ab"
   },
   "outputs": [],
   "source": [
    "df['total_open_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df899966",
   "metadata": {
    "id": "df899966"
   },
   "source": [
    "### Convert all CAD into USD currency of \"total_open_amount\" column\n",
    "\n",
    "- 1 CAD = 0.7 USD\n",
    "- Create a new column i.e \"converted_usd\" and store USD and convered CAD to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2f1c5",
   "metadata": {
    "id": "8eb2f1c5"
   },
   "outputs": [],
   "source": [
    "df['converted_usd'] = df['total_open_amount'].where(df['invoice_currency']=='USD', df['total_open_amount'] * 0.7)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6ef1d",
   "metadata": {
    "id": "f9f6ef1d"
   },
   "source": [
    "### Display the new \"converted_usd\" column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1a178",
   "metadata": {
    "id": "1fc1a178"
   },
   "outputs": [],
   "source": [
    "df['converted_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6XLXX17kayuy",
   "metadata": {
    "id": "6XLXX17kayuy"
   },
   "source": [
    "### Display year wise total number of record \n",
    "\n",
    "- Note -  use \"buisness_year\" column for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9f6ee",
   "metadata": {
    "id": "00c9f6ee"
   },
   "outputs": [],
   "source": [
    "df['buisness_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c35904",
   "metadata": {
    "id": "05c35904"
   },
   "source": [
    "### Write the code to delete the following columns \n",
    "\n",
    "- 'invoice_currency'\n",
    "- 'total_open_amount', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac28aa5",
   "metadata": {
    "id": "4ac28aa5"
   },
   "outputs": [],
   "source": [
    "df.drop(['invoice_currency','total_open_amount'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bDBJ_Kvwc086",
   "metadata": {
    "id": "bDBJ_Kvwc086"
   },
   "source": [
    "### Write a code to check the number of columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea360a8c",
   "metadata": {
    "id": "ea360a8c"
   },
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f63655",
   "metadata": {
    "id": "b8f63655"
   },
   "source": [
    "# Splitting the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f749d",
   "metadata": {
    "id": "a00f749d"
   },
   "source": [
    "### Look for all columns containing null value\n",
    "\n",
    "- Note - Output expected is only one column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c801e",
   "metadata": {
    "id": "148c801e"
   },
   "outputs": [],
   "source": [
    "print(df.columns[df.isna().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094a290",
   "metadata": {
    "id": "a094a290"
   },
   "source": [
    "#### Find out the number of null values from the column that you got from the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfb113",
   "metadata": {
    "id": "30bfb113"
   },
   "outputs": [],
   "source": [
    "df['clear_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d939b",
   "metadata": {
    "id": "7f6d939b"
   },
   "source": [
    "### On basis of the above column we are spliting data into dataset\n",
    "\n",
    "- First dataframe (refer that as maindata) only containing the rows, that have NO NULL data in that column ( This is going to be our train dataset ) \n",
    "- Second dataframe (refer that as nulldata) that contains the columns, that have Null data in that column ( This is going to be our test dataset ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8764c33",
   "metadata": {
    "id": "c8764c33"
   },
   "outputs": [],
   "source": [
    "maindata=df.dropna()\n",
    "nulldata = df[df.clear_date.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3P8riRBHd_r6",
   "metadata": {
    "id": "3P8riRBHd_r6"
   },
   "source": [
    "### Check the number of Rows and Columns for both the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693a464",
   "metadata": {
    "id": "0693a464"
   },
   "outputs": [],
   "source": [
    "maindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86bc74",
   "metadata": {
    "id": "7f86bc74"
   },
   "outputs": [],
   "source": [
    "nulldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747165d",
   "metadata": {
    "id": "0747165d"
   },
   "source": [
    "### Display the 5 records from maindata and nulldata dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2ec36",
   "metadata": {
    "id": "dec2ec36"
   },
   "outputs": [],
   "source": [
    "maindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2d68a",
   "metadata": {
    "id": "eee2d68a"
   },
   "outputs": [],
   "source": [
    "nulldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa6746",
   "metadata": {
    "id": "24aa6746"
   },
   "source": [
    "## Considering the **maindata**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c4aa7",
   "metadata": {
    "id": "f92c4aa7"
   },
   "source": [
    "#### Generate a new column \"Delay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to create a new column 'Delay' from two existing columns, \"clear_date\" and \"due_in_date\" \n",
    "- Formula - Delay = clear_date - due_in_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeceb9c",
   "metadata": {
    "id": "8eeceb9c"
   },
   "outputs": [],
   "source": [
    "maindata['delay']=maindata['clear_date']-maindata['due_in_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482144e",
   "metadata": {
    "id": "f482144e"
   },
   "source": [
    "### Generate a new column \"avgdelay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to make a new column \"avgdelay\" by grouping \"name_customer\" column with reapect to mean of the \"Delay\" column.\n",
    "- This new column \"avg_delay\" is meant to store \"customer_name\" wise delay\n",
    "- groupby('name_customer')['Delay'].mean(numeric_only=False)\n",
    "- Display the new \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d2f8d",
   "metadata": {
    "id": "d18d2f8d"
   },
   "outputs": [],
   "source": [
    "avg_delay=maindata.groupby('name_customer')['delay'].mean(numeric_only=False)\n",
    "avg_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b995e8",
   "metadata": {
    "id": "64b995e8"
   },
   "source": [
    "You need to add the \"avg_delay\" column with the maindata, mapped with \"name_customer\" column\n",
    "\n",
    " - Note - You need to use map function to map the avgdelay with respect to \"name_customer\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1f3d9",
   "metadata": {
    "id": "e1e1f3d9"
   },
   "outputs": [],
   "source": [
    "maindata['avg_delay']=maindata['name_customer'].map(avg_delay)\n",
    "\n",
    "maindata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d332525",
   "metadata": {
    "id": "1d332525"
   },
   "source": [
    "### Observe that the \"avg_delay\" column is in days format. You need to change the format into seconds\n",
    "\n",
    "- Days_format :  17 days 00:00:00\n",
    "- Format in seconds : 1641600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ddc81",
   "metadata": {},
   "outputs": [],
   "source": [
    " maindata['avg_delay'] =maindata['avg_delay'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvgtHSsx_O-n",
   "metadata": {
    "id": "OvgtHSsx_O-n"
   },
   "source": [
    "### Display the maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca9c45",
   "metadata": {
    "id": "97ca9c45"
   },
   "outputs": [],
   "source": [
    "maindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cd644",
   "metadata": {},
   "outputs": [],
   "source": [
    "maindata['avg_delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24c7bb",
   "metadata": {
    "id": "ae24c7bb"
   },
   "source": [
    "### Since you have created the \"avg_delay\" column from \"Delay\" and \"clear_date\" column, there is no need of these two columns anymore \n",
    "\n",
    "- You are expected to drop \"Delay\" and \"clear_date\" columns from maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a61ab9",
   "metadata": {
    "id": "78a61ab9"
   },
   "outputs": [],
   "source": [
    "maindata.drop(['delay','clear_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae724bfc",
   "metadata": {
    "id": "ae724bfc"
   },
   "source": [
    "# Splitting of Train and the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f0264",
   "metadata": {
    "id": "cb6f0264"
   },
   "source": [
    "### You need to split the \"maindata\" columns into X and y dataframe\n",
    "\n",
    "- Note - y should have the target column i.e. \"avg_delay\" and the other column should be in X\n",
    "\n",
    "- X is going to hold the source fields and y will be going to hold the target fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab29ab",
   "metadata": {
    "id": "75ab29ab"
   },
   "outputs": [],
   "source": [
    "X=maindata.drop(['avg_delay'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412c62b",
   "metadata": {
    "id": "6412c62b"
   },
   "outputs": [],
   "source": [
    "y=maindata['avg_delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2942bf",
   "metadata": {
    "id": "1c2942bf"
   },
   "source": [
    "#### You are expected to split both the dataframes into train and test format in 60:40 ratio \n",
    "\n",
    "- Note - The expected output should be in \"X_train\", \"X_loc_test\", \"y_train\", \"y_loc_test\" format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92160a5",
   "metadata": {
    "id": "d92160a5"
   },
   "outputs": [],
   "source": [
    "X_train,X_loc_test,y_train,y_loc_test=train_test_split(X,y,train_size=0.60,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p4OME62pDufR",
   "metadata": {
    "id": "p4OME62pDufR"
   },
   "source": [
    "### Please check for the number of rows and columns of all the new dataframes (all 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48328d0a",
   "metadata": {
    "id": "48328d0a"
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_loc_test.shape,y_train.shape,y_loc_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68ed71",
   "metadata": {
    "id": "4a68ed71"
   },
   "source": [
    "### Now you are expected to split the \"X_loc_test\" and \"y_loc_test\" dataset into \"Test\" and \"Validation\" (as the names given below) dataframe with 50:50 format \n",
    "\n",
    "- Note - The expected output should be in \"X_val\", \"X_test\", \"y_val\", \"y_test\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c62f2",
   "metadata": {
    "id": "b56c62f2"
   },
   "outputs": [],
   "source": [
    "X_val,X_test,y_val,y_test=train_test_split(X_loc_test,y_loc_test,train_size=0.50,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bJTSAskvERH1",
   "metadata": {
    "id": "bJTSAskvERH1"
   },
   "source": [
    "### Please check for the number of rows and columns of all the 4 dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d7564",
   "metadata": {
    "id": "845d7564"
   },
   "outputs": [],
   "source": [
    "X_val.shape,X_test.shape,y_val.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fa872",
   "metadata": {
    "id": "110fa872"
   },
   "source": [
    "# Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8fe0f",
   "metadata": {
    "id": "ffc8fe0f"
   },
   "source": [
    "### Distribution Plot of the target variable (use the dataframe which contains the target field)\n",
    "\n",
    "- Note - You are expected to make a distribution plot for the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bf8ed",
   "metadata": {
    "id": "ba2bf8ed"
   },
   "outputs": [],
   "source": [
    "sns.distplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e323a3",
   "metadata": {
    "id": "d0e323a3"
   },
   "source": [
    "### You are expected to group the X_train dataset on 'name_customer' column with 'doc_id' in the x_train set\n",
    "\n",
    "### Need to store the outcome into a new dataframe \n",
    "\n",
    "- Note code given for groupby statement- X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acf0ee",
   "metadata": {
    "id": "f7acf0ee"
   },
   "outputs": [],
   "source": [
    "X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cA43bFffFt6i",
   "metadata": {
    "id": "cA43bFffFt6i"
   },
   "source": [
    "### You can make another distribution plot of the \"doc_id\" column from x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576bf33",
   "metadata": {
    "id": "9576bf33"
   },
   "outputs": [],
   "source": [
    "sns.distplot(X_train['doc_id'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba2c44f",
   "metadata": {
    "id": "fba2c44f"
   },
   "source": [
    "#### Create a Distribution plot only for business_year and a seperate distribution plot of \"business_year\" column along with the doc_id\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecec77",
   "metadata": {
    "id": "4fecec77"
   },
   "outputs": [],
   "source": [
    "sns.distplot(X_train['buisness_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968fbcc9",
   "metadata": {
    "id": "968fbcc9"
   },
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jbh6CyGqH3XE",
   "metadata": {
    "id": "jbh6CyGqH3XE"
   },
   "source": [
    "### Display and describe the X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcf307",
   "metadata": {
    "id": "e6bcf307"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc819",
   "metadata": {
    "id": "08ccc819"
   },
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7ac8b",
   "metadata": {
    "id": "abd7ac8b"
   },
   "source": [
    "#### The \"business_code\" column inside X_train, is a categorical column, so you need to perform Labelencoder on that particular column\n",
    "\n",
    "- Note - call the Label Encoder from sklearn library and use the fit() function on \"business_code\" column\n",
    "- Note - Please fill in the blanks (two) to complete this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c223545",
   "metadata": {
    "id": "7c223545"
   },
   "outputs": [],
   "source": [
    "business_coder = LabelEncoder()\n",
    "business_coder.fit(X_train['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f7d9c",
   "metadata": {
    "id": "f86f7d9c"
   },
   "source": [
    "#### You are expected to store the value into a new column i.e. \"business_code_enc\"\n",
    "\n",
    "- Note - For Training set you are expected to use fit_trainsform()\n",
    "- Note - For Test set you are expected to use the trainsform()\n",
    "- Note - For Validation set you are expected to use the trainsform()\n",
    "\n",
    "\n",
    "- Partial code is provided, please fill in the blanks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269c307",
   "metadata": {
    "id": "4269c307"
   },
   "outputs": [],
   "source": [
    "X_train['business_code_enc'] = business_coder.fit_transform(X_train['business_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a53712",
   "metadata": {
    "id": "70a53712"
   },
   "outputs": [],
   "source": [
    "X_val['business_code_enc'] = business_coder.transform(X_val['business_code'])\n",
    "X_test['business_code_enc'] = business_coder.transform(X_test['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gdNYxTkqNfmz",
   "metadata": {
    "id": "gdNYxTkqNfmz"
   },
   "source": [
    "### Display \"business_code\" and \"business_code_enc\" together from X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196a002",
   "metadata": {
    "id": "1196a002"
   },
   "outputs": [],
   "source": [
    "X_train[['business_code','business_code_enc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11477224",
   "metadata": {
    "id": "11477224"
   },
   "source": [
    "#### Create a function called \"custom\" for dropping the columns 'business_code' from train, test and validation dataframe\n",
    "\n",
    "- Note - Fill in the blank to complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052868a",
   "metadata": {
    "id": "1052868a"
   },
   "outputs": [],
   "source": [
    "def custom(col ,traindf = X_train,valdf = X_val,testdf = X_test):\n",
    "    traindf.drop(col, axis =1,inplace=True)\n",
    "    valdf.drop(col,axis=1 , inplace=True)\n",
    "    testdf.drop(col,axis=1 , inplace=True)\n",
    "\n",
    "    return traindf,valdf ,testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rI--ZuMbNLne",
   "metadata": {
    "id": "rI--ZuMbNLne"
   },
   "source": [
    "### Call the function by passing the column name which needed to be dropped from train, test and validation dataframes. Return updated dataframes to be stored in X_train ,X_val, X_test  \n",
    "\n",
    "- Note = Fill in the blank to complete the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f955c",
   "metadata": {
    "id": "1a0f955c"
   },
   "outputs": [],
   "source": [
    " X_train, X_val , X_test = custom(['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5b27e",
   "metadata": {
    "id": "28b5b27e"
   },
   "source": [
    "### Manually replacing str values with numbers, Here we are trying manually replace the customer numbers with some specific values like, 'CCCA' as 1, 'CCU' as 2 and so on. Also we are converting the datatype \"cust_number\" field to int type.\n",
    "\n",
    "- We are doing it for all the three dataframes as shown below. This is fully completed code. No need to modify anything here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd129e",
   "metadata": {
    "id": "85dd129e"
   },
   "outputs": [],
   "source": [
    "X_train['cust_number'] = X_train['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_test['cust_number'] = X_test['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_val['cust_number'] = X_val['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U8vA-zmdPnJ8",
   "metadata": {
    "id": "U8vA-zmdPnJ8"
   },
   "source": [
    "#### It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]. Unknown will be added in fit and transform will take care of new item. It gives unknown class id.\n",
    "\n",
    "#### This will fit the encoder for all the unique values and introduce unknown value\n",
    "\n",
    "- Note - Keep this code as it is, we will be using this later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f48ba",
   "metadata": {
    "id": "151f48ba"
   },
   "outputs": [],
   "source": [
    "#For encoding unseen labels\n",
    "class EncoderExt(object):\n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    def fit(self, data_list):\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "        return self\n",
    "    def transform(self, data_list):\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "        return self.label_encoder.transform(new_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c64e6",
   "metadata": {
    "id": "254c64e6"
   },
   "source": [
    "### Use the user define Label Encoder function called \"EncoderExt\" for the \"name_customer\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b17eff",
   "metadata": {
    "id": "62b17eff"
   },
   "outputs": [],
   "source": [
    "label_encoder = EncoderExt()\n",
    "label_encoder.fit(X_train['name_customer'])\n",
    "X_train['name_customer_enc']=label_encoder.transform(X_train['name_customer'])\n",
    "X_val['name_customer_enc']=label_encoder.transform(X_val['name_customer'])\n",
    "X_test['name_customer_enc']=label_encoder.transform(X_test['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mK7LMoy2QZhy",
   "metadata": {
    "id": "mK7LMoy2QZhy"
   },
   "source": [
    "### As we have created the a new column \"name_customer_enc\", so now drop \"name_customer\" column from all three dataframes\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85f1c0",
   "metadata": {
    "id": "ef85f1c0"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa09d22",
   "metadata": {
    "id": "3aa09d22"
   },
   "source": [
    "### Using Label Encoder for the \"cust_payment_terms\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ab642",
   "metadata": {
    "id": "6f9ab642"
   },
   "outputs": [],
   "source": [
    "label_encoder1 = EncoderExt()\n",
    "label_encoder1.fit(X_train['cust_payment_terms'])\n",
    "X_train['cust_payment_terms_enc']=label_encoder1.transform(X_train['cust_payment_terms'])\n",
    "X_val['cust_payment_terms_enc']=label_encoder1.transform(X_val['cust_payment_terms'])\n",
    "X_test['cust_payment_terms_enc']=label_encoder1.transform(X_test['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9a7c2",
   "metadata": {
    "id": "55f9a7c2"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788f42b",
   "metadata": {
    "id": "0788f42b"
   },
   "source": [
    "## Check the datatype of all the columns of Train, Test and Validation dataframes realted to X\n",
    "\n",
    "- Note - You are expected yo use dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79a316",
   "metadata": {
    "id": "bc79a316"
   },
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33242d8",
   "metadata": {
    "id": "b33242d8"
   },
   "outputs": [],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4da71",
   "metadata": {
    "id": "6bd4da71"
   },
   "outputs": [],
   "source": [
    "X_val.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LVfvuPiWPeMB",
   "metadata": {
    "id": "LVfvuPiWPeMB"
   },
   "source": [
    "### From the above output you can notice their are multiple date columns with datetime format\n",
    "\n",
    "### In order to pass it into our model, we need to convert it into float format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d344db9",
   "metadata": {
    "id": "9d344db9"
   },
   "source": [
    "### You need to extract day, month and year from the \"posting_date\" column \n",
    "\n",
    "1.   Extract days from \"posting_date\" column and store it into a new column \"day_of_postingdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"posting_date\" column and store it into a new column \"month_of_postingdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"posting_date\" column and store it into a new column \"year_of_postingdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cdfd6",
   "metadata": {
    "id": "6e3cdfd6"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_postingdate'] = X_train['posting_date'].dt.day\n",
    "X_train['month_of_postingdate'] = X_train['posting_date'].dt.month\n",
    "X_train['year_of_postingdate'] = X_train['posting_date'].dt.year\n",
    "\n",
    "X_val['day_of_postingdate'] = X_val['posting_date'].dt.day\n",
    "X_val['month_of_postingdate'] = X_val['posting_date'].dt.month\n",
    "X_val['year_of_postingdate'] = X_val['posting_date'].dt.year\n",
    "\n",
    "X_test['day_of_postingdate'] = X_test['posting_date'].dt.day\n",
    "X_test['month_of_postingdate'] = X_test['posting_date'].dt.month\n",
    "X_test['year_of_postingdate'] = X_test['posting_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GyI-F853Rxa7",
   "metadata": {
    "id": "GyI-F853Rxa7"
   },
   "source": [
    "### pass the \"posting_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQHtQkrnRx_V",
   "metadata": {
    "id": "FQHtQkrnRx_V"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['posting_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GMnCaEcKReSw",
   "metadata": {
    "id": "GMnCaEcKReSw"
   },
   "source": [
    "### You need to extract day, month and year from the \"baseline_create_date\" column \n",
    "\n",
    "1.   Extract days from \"baseline_create_date\" column and store it into a new column \"day_of_createdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"baseline_create_date\" column and store it into a new column \"month_of_createdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"baseline_create_date\" column and store it into a new column \"year_of_createdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "- Note - Do as it is been shown in the previous two code boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d83d0",
   "metadata": {
    "id": "ee4d83d0"
   },
   "source": [
    "### Extracting Day, Month, Year for 'baseline_create_date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b240e1",
   "metadata": {
    "id": "32b240e1"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_baselinedate'] = X_train['baseline_create_date'].dt.day\n",
    "X_train['month_of_baselinedate'] = X_train['baseline_create_date'].dt.month\n",
    "X_train['year_of_baselinedate'] = X_train['baseline_create_date'].dt.year\n",
    "\n",
    "X_val['day_of_baselinedate'] = X_val['baseline_create_date'].dt.day\n",
    "X_val['month_of_baselinedate'] = X_val['baseline_create_date'].dt.month\n",
    "X_val['year_of_baselinedate'] = X_val['baseline_create_date'].dt.year\n",
    "\n",
    "X_test['day_of_baselinedate'] = X_test['baseline_create_date'].dt.day\n",
    "X_test['month_of_baselinedate'] = X_test['baseline_create_date'].dt.month\n",
    "X_test['year_of_baselinedate'] = X_test['baseline_create_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFgwkS5rSDDs",
   "metadata": {
    "id": "cFgwkS5rSDDs"
   },
   "source": [
    "### pass the \"baseline_create_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGYa2BEQSDg3",
   "metadata": {
    "id": "RGYa2BEQSDg3"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['baseline_create_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7a0df",
   "metadata": {
    "id": "77c7a0df"
   },
   "source": [
    "### You need to extract day, month and year from the \"due_in_date\" column \n",
    "\n",
    "1.   Extract days from \"due_in_date\" column and store it into a new column \"day_of_due\" for train, test and validation dataset \n",
    "2.   Extract months from \"due_in_date\" column and store it into a new column \"month_of_due\" for train, test and validation dataset\n",
    "3.   Extract year from \"due_in_date\" column and store it into a new column \"year_of_due\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "- Note - Do as it is been shown in the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c745547",
   "metadata": {
    "id": "5c745547"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_dueindate'] = X_train['due_in_date'].dt.day\n",
    "X_train['month_of_dueindate'] = X_train['due_in_date'].dt.month\n",
    "X_train['year_of_dueindate'] = X_train['due_in_date'].dt.year\n",
    "\n",
    "X_val['day_of_dueindate'] = X_val['due_in_date'].dt.day\n",
    "X_val['month_of_dueindate'] = X_val['due_in_date'].dt.month\n",
    "X_val['year_of_dueindate'] = X_val['due_in_date'].dt.year\n",
    "\n",
    "X_test['day_of_dueindate'] = X_test['due_in_date'].dt.day\n",
    "X_test['month_of_dueindate'] = X_test['due_in_date'].dt.month\n",
    "X_test['year_of_dueindate'] = X_test['due_in_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FYLLzulGSvRd",
   "metadata": {
    "id": "FYLLzulGSvRd"
   },
   "source": [
    "pass the \"due_in_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1-s6QuY9Svrh",
   "metadata": {
    "id": "1-s6QuY9Svrh"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['due_in_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5d052",
   "metadata": {
    "id": "1ae5d052"
   },
   "source": [
    "### Check for the datatypes for train, test and validation set again\n",
    "\n",
    "- Note - all the data type should be in either int64 or float64 format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9d828",
   "metadata": {
    "id": "aee9d828"
   },
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f017a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65810f55",
   "metadata": {
    "id": "65810f55"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1ad9f",
   "metadata": {
    "id": "4bb1ad9f"
   },
   "source": [
    "### Filter Method\n",
    "\n",
    "- Calling the VarianceThreshold Function \n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882509f",
   "metadata": {
    "id": "e882509f"
   },
   "outputs": [],
   "source": [
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)\n",
    "len(X_train.columns[constant_filter.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V9531H3jR-W2",
   "metadata": {
    "id": "V9531H3jR-W2"
   },
   "source": [
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c12e1",
   "metadata": {
    "id": "c77c12e1"
   },
   "outputs": [],
   "source": [
    "constant_columns = [column for column in X_train.columns\n",
    "                    if column not in X_train.columns[constant_filter.get_support()]]\n",
    "\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b8610",
   "metadata": {
    "id": "6d9b8610"
   },
   "source": [
    "- transpose the feature matrice\n",
    "- print the number of duplicated features\n",
    "- select the duplicated features columns names\n",
    "\n",
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7db95",
   "metadata": {
    "id": "0fb7db95"
   },
   "outputs": [],
   "source": [
    "x_train_T = X_train.T\n",
    "\n",
    "print(x_train_T.duplicated().sum())\n",
    "\n",
    "duplicated_columns = x_train_T[x_train_T.duplicated()].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fa831",
   "metadata": {
    "id": "510fa831"
   },
   "source": [
    "### Filtering depending upon correlation matrix value\n",
    "- We have created a function called handling correlation which is going to return fields based on the correlation matrix value with a threshold of 0.8\n",
    "\n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67731abc",
   "metadata": {
    "id": "67731abc"
   },
   "outputs": [],
   "source": [
    "def handling_correlation(X_train,threshold=0.8):\n",
    "    corr_features = set()\n",
    "    corr_matrix = X_train.corr()\n",
    "    for i in range(len(corr_matrix .columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                corr_features.add(colname)\n",
    "    return list(corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JaE_6qVgSXl3",
   "metadata": {
    "id": "JaE_6qVgSXl3"
   },
   "source": [
    "- Note : Here we are trying to find out the relevant fields, from X_train\n",
    "- Please fill in the blanks to call handling_correlation() function with a threshold value of 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91d1a2",
   "metadata": {
    "id": "dd91d1a2"
   },
   "outputs": [],
   "source": [
    "train=X_train.copy()\n",
    "handling_correlation(train.copy(),threshold=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154da511",
   "metadata": {
    "id": "154da511"
   },
   "source": [
    "### Heatmap for X_train\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f2fe4",
   "metadata": {
    "id": "2e8f2fe4"
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=20)\n",
    "sns.heatmap(X_train.merge(y_train , on = X_train.index ).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap='gist_rainbow_r', linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0d745",
   "metadata": {
    "id": "e3b0d745"
   },
   "source": [
    "#### Calling variance threshold for threshold value = 0.8\n",
    "\n",
    "- Note -  Fill in the blanks to call the appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2080f",
   "metadata": {
    "id": "a9b2080f"
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(0.8)\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8c3dc",
   "metadata": {
    "id": "6cb8c3dc"
   },
   "outputs": [],
   "source": [
    "sel.variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62633a84",
   "metadata": {
    "id": "62633a84"
   },
   "source": [
    "### Features columns are \n",
    "- 'year_of_createdate' \n",
    "- 'year_of_due'\n",
    "- 'day_of_createdate'\n",
    "- 'year_of_postingdate'\n",
    "- 'month_of_due'\n",
    "- 'month_of_createdate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f1ad0",
   "metadata": {
    "id": "651f1ad0"
   },
   "source": [
    "# Modelling \n",
    "\n",
    "#### Now you need to compare with different machine learning models, and needs to find out the best predicted model\n",
    "\n",
    "- Linear Regression\n",
    "- Decision Tree Regression\n",
    "- Random Forest Regression\n",
    "- Support Vector Regression\n",
    "- Extreme Gradient Boost Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PicEhSuUUOkt",
   "metadata": {
    "id": "PicEhSuUUOkt"
   },
   "source": [
    "### You need to make different blank list for different evaluation matrix \n",
    "\n",
    "- MSE\n",
    "- R2\n",
    "- Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e12b0",
   "metadata": {
    "id": "701e12b0"
   },
   "outputs": [],
   "source": [
    "MSE_Score = []\n",
    "R2_Score = []\n",
    "Algorithm = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29310119",
   "metadata": {
    "id": "29310119"
   },
   "source": [
    "### You need to start with the baseline model Linear Regression\n",
    "\n",
    "- Step 1 : Call the Linear Regression from sklearn library\n",
    "- Step 2 : make an object of Linear Regression \n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdea395",
   "metadata": {
    "id": "6bdea395"
   },
   "outputs": [],
   "source": [
    "Algorithm.append('LinearRegression')\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G02cpnBhXJ14",
   "metadata": {
    "id": "G02cpnBhXJ14"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69ca19",
   "metadata": {
    "id": "0f69ca19"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CsmScbHjYMv1",
   "metadata": {
    "id": "CsmScbHjYMv1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe653295",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1643093994094,
     "user": {
      "displayName": "Chandramouli Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsMuDXf6PZsS77v0Q5x8metxFPnlLXsBC6Y3O7=s64",
      "userId": "13777762579346461395"
     },
     "user_tz": -330
    },
    "id": "fe653295",
    "outputId": "0c7429ca-50d0-42a2-96a1-effaa92f549e"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LokxV2LGYUVh",
   "metadata": {
    "id": "LokxV2LGYUVh"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c405bd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1643093994095,
     "user": {
      "displayName": "Chandramouli Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsMuDXf6PZsS77v0Q5x8metxFPnlLXsBC6Y3O7=s64",
      "userId": "13777762579346461395"
     },
     "user_tz": -330
    },
    "id": "9c405bd3",
    "outputId": "9d78f4a9-33fc-48d1-edc8-c997eca38de0"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e65c86",
   "metadata": {
    "id": "b0e65c86"
   },
   "source": [
    "### You need to start with the baseline model Support Vector Regression\n",
    "\n",
    "- Step 1 : Call the Support Vector Regressor from sklearn library\n",
    "- Step 2 : make an object of SVR\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5de08",
   "metadata": {
    "id": "ccb5de08"
   },
   "outputs": [],
   "source": [
    "Algorithm.append('SVR')\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "predicted= svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zz9kcrViYt7e",
   "metadata": {
    "id": "zz9kcrViYt7e"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for \"y_test\" and \"predicted\" dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9db76",
   "metadata": {
    "id": "5bb9db76"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0YAxd8N9Y0hJ",
   "metadata": {
    "id": "0YAxd8N9Y0hJ"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee71b1",
   "metadata": {
    "id": "d6ee71b1"
   },
   "outputs": [],
   "source": [
    "predict_test= svr.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eGcqS5EcY4BI",
   "metadata": {
    "id": "eGcqS5EcY4BI"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72c1ec",
   "metadata": {
    "id": "aa72c1ec"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad18bb3",
   "metadata": {
    "id": "dad18bb3"
   },
   "source": [
    "### Your next model would be Decision Tree Regression\n",
    "\n",
    "- Step 1 : Call the Decision Tree Regressor from sklearn library\n",
    "- Step 2 : make an object of Decision Tree\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a51eb",
   "metadata": {
    "id": "1b6a51eb"
   },
   "outputs": [],
   "source": [
    "Algorithm.append('Decision Tree Regressor')\n",
    "DTR = DecisionTreeRegressor()\n",
    "DTR.fit(X_train, y_train)\n",
    "predicted= DTR.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AOzfgfeOZo3F",
   "metadata": {
    "id": "AOzfgfeOZo3F"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e6983",
   "metadata": {
    "id": "776e6983"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eI6d49DQZrhW",
   "metadata": {
    "id": "eI6d49DQZrhW"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fb55c",
   "metadata": {
    "id": "155fb55c"
   },
   "outputs": [],
   "source": [
    "predict_test= DTR.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbGXvBLQZw5E",
   "metadata": {
    "id": "sbGXvBLQZw5E"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74d515",
   "metadata": {
    "id": "1d74d515"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9979b",
   "metadata": {
    "id": "4ae9979b"
   },
   "source": [
    "### Your next model would be Random Forest Regression\n",
    "\n",
    "- Step 1 : Call the Random Forest Regressor from sklearn library\n",
    "- Step 2 : make an object of Random Forest\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e476a",
   "metadata": {
    "id": "a69e476a"
   },
   "outputs": [],
   "source": [
    "Algorithm.append('Random Forest Regressor')\n",
    "RFR = RandomForestRegressor()\n",
    "RFR.fit(X_train, y_train)\n",
    "predicted= RFR.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XNcEJF-6anof",
   "metadata": {
    "id": "XNcEJF-6anof"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f63f4",
   "metadata": {
    "id": "826f63f4"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yMbyr9V4ati1",
   "metadata": {
    "id": "yMbyr9V4ati1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9fb54",
   "metadata": {
    "id": "55b9fb54"
   },
   "outputs": [],
   "source": [
    "predict_test= RFR.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiBawcCsaw_Z",
   "metadata": {
    "id": "tiBawcCsaw_Z"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277c13e",
   "metadata": {
    "id": "8277c13e"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b21881",
   "metadata": {
    "id": "e6b21881"
   },
   "source": [
    "### The last but not the least model would be XGBoost or Extreme Gradient Boost Regression\n",
    "\n",
    "- Step 1 : Call the XGBoost Regressor from xgb library\n",
    "- Step 2 : make an object of Xgboost\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose### Extreme Gradient Boost Regression\n",
    "- Note -  No need to change the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a38ec",
   "metadata": {
    "id": "705a38ec"
   },
   "outputs": [],
   "source": [
    "Algorithm.append('XGB Regressor')\n",
    "regressor = xgb.XGBRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ierNZkb9bQDD",
   "metadata": {
    "id": "ierNZkb9bQDD"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a9d2f",
   "metadata": {
    "id": "507a9d2f"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84UZ2ojsbWaH",
   "metadata": {
    "id": "84UZ2ojsbWaH"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ac250",
   "metadata": {
    "id": "e78ac250"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9FJFyaVbbbAH",
   "metadata": {
    "id": "9FJFyaVbbbAH"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765ba35",
   "metadata": {
    "id": "f765ba35"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71bc90f",
   "metadata": {
    "id": "a71bc90f"
   },
   "source": [
    "## You need to make the comparison list into a comparison dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5159a7",
   "metadata": {
    "id": "ff5159a7"
   },
   "outputs": [],
   "source": [
    "Comparison = pd.DataFrame(list(zip(Algorithm, MSE_Score, R2_Score)), columns = ['Algorithm', 'MSE_Score', 'R2_Score'])\n",
    "Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e61c60",
   "metadata": {
    "id": "62e61c60"
   },
   "source": [
    "## Now from the Comparison table, you need to choose the best fit model\n",
    "\n",
    "- Step 1 - Fit X_train and y_train inside the model \n",
    "- Step 2 - Predict the X_test dataset\n",
    "- Step 3 - Predict the X_val dataset\n",
    "\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07c258",
   "metadata": {
    "id": "3e07c258"
   },
   "outputs": [],
   "source": [
    "regressorfinal = xgb.XGBRegressor()\n",
    "regressorfinal.fit(X_train, y_train)\n",
    "predictedfinal = regressorfinal.predict(X_test)\n",
    "predict_testfinal = regressorfinal.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4df6c4",
   "metadata": {
    "id": "8e4df6c4"
   },
   "source": [
    "### Calculate the Mean Square Error for test dataset\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb466d0",
   "metadata": {
    "id": "5fb466d0"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,predictedfinal,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27f87f",
   "metadata": {
    "id": "ce27f87f"
   },
   "source": [
    "### Calculate the mean Square Error for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47978ea",
   "metadata": {
    "id": "b47978ea"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_val,predictedfinal,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30014dbd",
   "metadata": {
    "id": "30014dbd"
   },
   "source": [
    "### Calculate the R2 score for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a162737",
   "metadata": {
    "id": "8a162737"
   },
   "outputs": [],
   "source": [
    "r2_score(y_test,predictedfinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9853b0",
   "metadata": {
    "id": "1c9853b0"
   },
   "source": [
    "### Calculate the R2 score for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6dc77c",
   "metadata": {
    "id": "1a6dc77c"
   },
   "outputs": [],
   "source": [
    "r2_score(y_val,predictedfinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499522d9",
   "metadata": {
    "id": "499522d9"
   },
   "source": [
    "### Calculate the Accuracy for train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f1ce8",
   "metadata": {
    "id": "7a4f1ce8"
   },
   "outputs": [],
   "source": [
    "regressorfinal.score(X_train,y_train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1c921",
   "metadata": {
    "id": "12a1c921"
   },
   "source": [
    "### Calculate the accuracy for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2579b4f",
   "metadata": {
    "id": "d2579b4f"
   },
   "outputs": [],
   "source": [
    "regressorfinal.score(X_val,y_val)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b82e84",
   "metadata": {
    "id": "79b82e84"
   },
   "source": [
    "### Calculate the accuracy for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e6431",
   "metadata": {
    "id": "f09e6431"
   },
   "outputs": [],
   "source": [
    "regressorfinal.score(X_test,y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488a5d9",
   "metadata": {
    "id": "9488a5d9"
   },
   "source": [
    "## Specify the reason behind choosing your machine learning model \n",
    "\n",
    "- Note : Provide your answer as a text here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a6519",
   "metadata": {
    "id": "387a6519"
   },
   "source": [
    "## Now you need to pass the Nulldata dataframe into this machine learning model\n",
    "\n",
    "#### In order to pass this Nulldata dataframe into the ML model, we need to perform the following\n",
    "\n",
    "- Step 1 : Label Encoding \n",
    "- Step 2 : Day, Month and Year extraction \n",
    "- Step 3 : Change all the column data type into int64 or float64\n",
    "- Step 4 : Need to drop the useless columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I7JuxAkdiAdI",
   "metadata": {
    "id": "I7JuxAkdiAdI"
   },
   "source": [
    "### Display the Nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a51d2",
   "metadata": {
    "id": "6d6a51d2"
   },
   "outputs": [],
   "source": [
    "nulldata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vamx5xqtiHCH",
   "metadata": {
    "id": "Vamx5xqtiHCH"
   },
   "source": [
    "### Check for the number of rows and columns in the nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de1092",
   "metadata": {
    "id": "59de1092"
   },
   "outputs": [],
   "source": [
    "nulldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BxzHNbBjpqXL",
   "metadata": {
    "id": "BxzHNbBjpqXL"
   },
   "source": [
    "### Check the Description and Information of the nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb86c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294d29",
   "metadata": {
    "id": "a6294d29"
   },
   "outputs": [],
   "source": [
    "nulldata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe860d94",
   "metadata": {
    "id": "fe860d94"
   },
   "source": [
    "### Storing the Nulldata into a different dataset \n",
    "# for BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16352034",
   "metadata": {
    "id": "16352034"
   },
   "outputs": [],
   "source": [
    "nulldata_copy=nulldata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f35b8c",
   "metadata": {
    "id": "00f35b8c"
   },
   "source": [
    "### Call the Label Encoder for Nulldata\n",
    "\n",
    "- Note - you are expected to fit \"business_code\" as it is a categorical variable\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf04b17",
   "metadata": {
    "id": "baf04b17"
   },
   "outputs": [],
   "source": [
    "business_codern = LabelEncoder()\n",
    "business_codern.fit(nulldata['business_code'])\n",
    "nulldata['business_code_enc'] = business_codern.transform(nulldata['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZCPBK9karIR-",
   "metadata": {
    "id": "ZCPBK9karIR-"
   },
   "source": [
    "### Now you need to manually replacing str values with numbers\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64924be",
   "metadata": {
    "id": "c64924be"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_number'] = nulldata['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55f5f6",
   "metadata": {
    "id": "9a55f5f6"
   },
   "source": [
    "## You need to extract day, month and year from the \"clear_date\", \"posting_date\", \"due_in_date\", \"baseline_create_date\" columns\n",
    "\n",
    "\n",
    "##### 1.   Extract day from \"clear_date\" column and store it into 'day_of_cleardate'\n",
    "##### 2.   Extract month from \"clear_date\" column and store it into 'month_of_cleardate'\n",
    "##### 3.   Extract year from \"clear_date\" column and store it into 'year_of_cleardate'\n",
    "\n",
    "\n",
    "\n",
    "##### 4.   Extract day from \"posting_date\" column and store it into 'day_of_postingdate'\n",
    "##### 5.   Extract month from \"posting_date\" column and store it into 'month_of_postingdate'\n",
    "##### 6.   Extract year from \"posting_date\" column and store it into 'year_of_postingdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 7.   Extract day from \"due_in_date\" column and store it into 'day_of_due'\n",
    "##### 8.   Extract month from \"due_in_date\" column and store it into 'month_of_due'\n",
    "##### 9.   Extract year from \"due_in_date\" column and store it into 'year_of_due'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 10.   Extract day from \"baseline_create_date\" column and store it into 'day_of_createdate'\n",
    "##### 11.   Extract month from \"baseline_create_date\" column and store it into 'month_of_createdate'\n",
    "##### 12.   Extract year from \"baseline_create_date\" column and store it into 'year_of_createdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed To use - \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166fbe4",
   "metadata": {
    "id": "4166fbe4"
   },
   "outputs": [],
   "source": [
    "nulldata['day_of_cleardate'] = nulldata['clear_date'].dt.day\n",
    "nulldata['month_of_cleardate'] = nulldata['clear_date'].dt.month\n",
    "nulldata['year_of_cleardate'] = nulldata['clear_date'].dt.year\n",
    "\n",
    "nulldata['day_of_postingdate'] = nulldata['posting_date'].dt.day\n",
    "nulldata['month_of_postingdate'] = nulldata['posting_date'].dt.month\n",
    "nulldata['year_of_postingdate'] = nulldata['posting_date'].dt.year\n",
    "\n",
    "nulldata['day_of_due'] = nulldata['due_in_date'].dt.day\n",
    "nulldata['month_of_due'] = nulldata['due_in_date'].dt.month\n",
    "nulldata['year_of_due'] = nulldata['due_in_date'].dt.year\n",
    "\n",
    "nulldata['day_of_createdate'] = nulldata['baseline_create_date'].dt.day\n",
    "nulldata['month_of_createdate'] = nulldata['baseline_create_date'].dt.month\n",
    "nulldata['year_of_createdate'] = nulldata['baseline_create_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QeHWJYrAvOC6",
   "metadata": {
    "id": "QeHWJYrAvOC6"
   },
   "source": [
    "### Use Label Encoder1 of all the following columns - \n",
    "- 'cust_payment_terms' and store into 'cust_payment_terms_enc'\n",
    "- 'business_code' and store into 'business_code_enc'\n",
    "- 'name_customer' and store into 'name_customer_enc'\n",
    "\n",
    "Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac330e2",
   "metadata": {
    "id": "bac330e2"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_payment_terms_enc']=label_encoder1.transform(nulldata['cust_payment_terms'])\n",
    "nulldata['business_code_enc']=label_encoder1.transform(nulldata['business_code'])\n",
    "nulldata['name_customer_enc']=label_encoder.transform(nulldata['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zD9I-XqQwC28",
   "metadata": {
    "id": "zD9I-XqQwC28"
   },
   "source": [
    "### Check for the datatypes of all the columns of Nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f72517",
   "metadata": {
    "id": "d4f72517"
   },
   "outputs": [],
   "source": [
    "nulldata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd5452",
   "metadata": {
    "id": "17cd5452"
   },
   "source": [
    "### Now you need to drop all the unnecessary columns - \n",
    "\n",
    "- 'business_code'\n",
    "- \"baseline_create_date\"\n",
    "- \"due_in_date\"\n",
    "- \"posting_date\"\n",
    "- \"name_customer\"\n",
    "- \"clear_date\"\n",
    "- \"cust_payment_terms\"\n",
    "- 'day_of_cleardate'\n",
    "- \"month_of_cleardate\"\n",
    "- \"year_of_cleardate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c82076",
   "metadata": {
    "id": "d7c82076"
   },
   "outputs": [],
   "source": [
    "nulldata.drop(['business_code',\"baseline_create_date\",\"due_in_date\",\"posting_date\",\"name_customer\",\"clear_date\",\"cust_payment_terms\",'day_of_cleardate',\"month_of_cleardate\",\"year_of_cleardate\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q_NCr9IPweVq",
   "metadata": {
    "id": "Q_NCr9IPweVq"
   },
   "source": [
    "### Check the information of the \"nulldata\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ffee0",
   "metadata": {
    "id": "4e7ffee0"
   },
   "outputs": [],
   "source": [
    "nulldata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-XvjhWqmwi-C",
   "metadata": {
    "id": "-XvjhWqmwi-C"
   },
   "source": [
    "### Compare \"nulldata\" with the \"X_test\" dataframe \n",
    "\n",
    "- use info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4b62d",
   "metadata": {
    "id": "02f4b62d"
   },
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Us3ey-9zwqjq",
   "metadata": {
    "id": "Us3ey-9zwqjq"
   },
   "source": [
    "### You must have noticed that there is a mismatch in the column sequence while compairing the dataframes\n",
    "\n",
    "- Note - In order to fed into the machine learning model, you need to edit the sequence of \"nulldata\", similar to the \"X_test\" dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vduVNt1kxPW-",
   "metadata": {
    "id": "vduVNt1kxPW-"
   },
   "source": [
    "- Display all the columns of the X_test dataframe \n",
    "- Display all the columns of the Nulldata dataframe \n",
    "- Store the Nulldata with new sequence into a new dataframe \n",
    "\n",
    "\n",
    "- Note - The code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729353e",
   "metadata": {
    "id": "6729353e"
   },
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd9c5e",
   "metadata": {
    "id": "47bd9c5e"
   },
   "outputs": [],
   "source": [
    "nulldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a2103",
   "metadata": {
    "id": "aa5a2103"
   },
   "outputs": [],
   "source": [
    "nulldata2=nulldata[['cust_number', 'buisness_year', 'doc_id', 'converted_usd',\n",
    "       'business_code_enc', 'name_customer_enc', 'cust_payment_terms_enc',\n",
    "       'day_of_postingdate', 'month_of_postingdate', 'year_of_postingdate',\n",
    "       'day_of_createdate', 'month_of_createdate', 'year_of_createdate',\n",
    "       'day_of_due', 'month_of_due', 'year_of_due']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8b021",
   "metadata": {
    "id": "1dc8b021"
   },
   "source": [
    "### Display the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39785a",
   "metadata": {
    "id": "2f39785a"
   },
   "outputs": [],
   "source": [
    "nulldata2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b88c5a",
   "metadata": {
    "id": "27b88c5a"
   },
   "source": [
    "### Now you can pass this dataset into you final model and store it into \"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b6388",
   "metadata": {
    "id": "9e0b6388"
   },
   "outputs": [],
   "source": [
    "final_result =regressorfinal.predict(nulldata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653d3c6",
   "metadata": {
    "id": "9653d3c6"
   },
   "source": [
    "### you need to make the final_result as dataframe, with a column name \"avg_delay\"\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef814d",
   "metadata": {
    "id": "25ef814d"
   },
   "outputs": [],
   "source": [
    "final_result = pd.Series(final_result,name='avg_delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C86staIhyf2C",
   "metadata": {
    "id": "C86staIhyf2C"
   },
   "source": [
    "### Display the \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd46406",
   "metadata": {
    "id": "4fd46406"
   },
   "outputs": [],
   "source": [
    "avg_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f71a7e",
   "metadata": {
    "id": "44f71a7e"
   },
   "source": [
    "### Now you need to merge this final_result dataframe with the BACKUP of \"nulldata\" Dataframe which we have created in earlier steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0969d",
   "metadata": {
    "id": "e8f0969d"
   },
   "outputs": [],
   "source": [
    "nulldata_copy.reset_index(drop=True,inplace=True)\n",
    "Final = nulldata_copy.merge(final_result , on = nulldata.index )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G-hLtxXgy4GZ",
   "metadata": {
    "id": "G-hLtxXgy4GZ"
   },
   "source": [
    "### Display the \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb4dc0",
   "metadata": {
    "id": "71fb4dc0"
   },
   "outputs": [],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4sc27Uz-y-0O",
   "metadata": {
    "id": "4sc27Uz-y-0O"
   },
   "source": [
    "### Check for the Number of Rows and Columns in your \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5iUXOIhzy_HR",
   "metadata": {
    "id": "5iUXOIhzy_HR"
   },
   "outputs": [],
   "source": [
    "Final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48886d2c",
   "metadata": {
    "id": "48886d2c"
   },
   "source": [
    "### Now, you need to do convert the below fields back into date and time format \n",
    "\n",
    "- Convert \"due_in_date\" into datetime format\n",
    "- Convert \"avg_delay\" into datetime format\n",
    "- Create a new column \"clear_date\" and store the sum of \"due_in_date\" and \"avg_delay\"\n",
    "- display the new \"clear_date\" column\n",
    "- Note - Code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243abc2d",
   "metadata": {
    "id": "243abc2d"
   },
   "outputs": [],
   "source": [
    "Final['clear_date'] = pd.to_datetime(Final['due_in_date']) + pd.to_timedelta(Final['avg_delay'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9QcX_fAjIkYR",
   "metadata": {
    "id": "9QcX_fAjIkYR"
   },
   "source": [
    "### Display the \"clear_date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcd029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final['clear_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MSkNLq6-z7rZ",
   "metadata": {
    "id": "MSkNLq6-z7rZ"
   },
   "source": [
    "### Convert the average delay into number of days format \n",
    "\n",
    "- Note - Formula = avg_delay//(24 * 3600)\n",
    "- Note - full code is given for this, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b618a",
   "metadata": {
    "id": "ce6b618a"
   },
   "outputs": [],
   "source": [
    "Final['avg_delay'] = Final.apply(lambda row: row.avg_delay//(24 * 3600), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wbBBZPjP0W7o",
   "metadata": {
    "id": "wbBBZPjP0W7o"
   },
   "source": [
    "### Display the \"avg_delay\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494982f",
   "metadata": {
    "id": "a494982f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final['avg_delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d8811",
   "metadata": {
    "id": "815d8811"
   },
   "source": [
    "### Now you need to convert average delay column into bucket\n",
    "\n",
    "- Need to perform binning \n",
    "- create a list of bins i.e. bins= [0,15,30,45,60,100]\n",
    "- create a list of labels i.e. labels = ['0-15','16-30','31-45','46-60','Greatar than 60']\n",
    "- perform binning by using cut() function from \"Final\" dataframe\n",
    "\n",
    "\n",
    "- Please fill up the first two rows of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797e4b5",
   "metadata": {
    "id": "c797e4b5"
   },
   "outputs": [],
   "source": [
    "bins= [0,15,30,45,60,100]\n",
    "labels = ['0-15','16-30','31-45','46-60','Greatar than 60']\n",
    "Final['Aging Bucket'] = pd.cut(Final['avg_delay'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35725f",
   "metadata": {
    "id": "1c35725f"
   },
   "source": [
    "### Now you need to drop \"key_0\" and \"avg_delay\" columns from the \"Final\" Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bc6a3",
   "metadata": {
    "id": "b31bc6a3"
   },
   "outputs": [],
   "source": [
    "Final.drop(['key_0','avg_delay'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ui-tyIvU0-5u",
   "metadata": {
    "id": "Ui-tyIvU0-5u"
   },
   "source": [
    "### Display the count of each categoty of new \"Aging Bucket\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e16218",
   "metadata": {
    "id": "a6e16218"
   },
   "outputs": [],
   "source": [
    "Final['Aging Bucket'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kgYegy551GKJ",
   "metadata": {
    "id": "kgYegy551GKJ"
   },
   "source": [
    "### Display your final dataset with aging buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc87ec",
   "metadata": {
    "id": "c4bc87ec"
   },
   "outputs": [],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ji7AoDCB1L_x",
   "metadata": {
    "id": "Ji7AoDCB1L_x"
   },
   "source": [
    "### Store this dataframe into the .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d0b8d",
   "metadata": {
    "id": "727d0b8d"
   },
   "outputs": [],
   "source": [
    "Final.to_csv('HRC62179WK_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FK0fabl61SkC",
   "metadata": {
    "id": "FK0fabl61SkC"
   },
   "source": [
    "# END OF THE PROJECT"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "62633a84"
   ],
   "name": "Payment date prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
